{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+OR2aNX6t2nQrTOIQp0Kj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahabubjamil/ColabNotebook/blob/main/201_15_13819.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "fCj40pgnT-fT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "NwA1IwsseDmW"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 10\n",
        "num_epochs = 3\n",
        "batch_size = 64\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "Sh9qqRavk9lM"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "VzasmUI9eeXG"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = torchvision.datasets.KMNIST(root='./data',train=True,\n",
        "                                       download=True, transform=transform)"
      ],
      "metadata": {
        "id": "R8guHHqWojlv"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                         shuffle=True)"
      ],
      "metadata": {
        "id": "kMIw9COCo1g2"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puTQ0FWKo270",
        "outputId": "efc41abf-2396-4108-d8bb-4c4c90712b60"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(trainloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kuetFwYnK-C",
        "outputId": "5b440c5e-5e4d-4e09-a063-9d70704e0f22"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "938"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testset = torchvision.datasets.KMNIST(root='./data',train=False,\n",
        "                                       download=True, transform=transform)"
      ],
      "metadata": {
        "id": "FvVZymUrpWS2"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False)"
      ],
      "metadata": {
        "id": "OAVoPWh8pc0e"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for X, y in trainloader:\n",
        "  print(X.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRBhRRrWnLxs",
        "outputId": "06e5adf7-9484-4fa3-e177-e11053d54878"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QloSODDIplmd",
        "outputId": "09483984-c84e-4ed1-ef44-c216a52779c1"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(testset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcB8GgqKpmJW",
        "outputId": "ce50446b-d9e7-4cf1-d1d9-94081768b9cc"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(ConvNet,self).__init__()\n",
        "        self.conv1= nn.Conv2d(3,6,5)\n",
        "        self.bn1=nn.BatchNorm2d(6)\n",
        "        self.conv2= nn.Conv2d(6,16,5)\n",
        "        self.bn2=nn.BatchNorm2d(16)\n",
        "        self.conv3= nn.Conv2d(3,6,5)\n",
        "        self.bn1=nn.BatchNorm2d(6)\n",
        "        self.conv4= nn.Conv2d(6,28,5)\n",
        "        self.bn2=nn.BatchNorm2d(28)\n",
        "\n",
        "        self.fc1= nn.Linear(28*5*5, 120) # 5*5 from image dimension\n",
        "        self.bn3=nn.BatchNorm1d(120)\n",
        "        self.fc2= nn.Linear(120,84)\n",
        "        self.bn4=nn.BatchNorm1d(84)\n",
        "        self.fc3= nn.Linear(84,10)\n",
        "\n",
        "    def forward(self, input):\n",
        "        x=self.conv1(input)\n",
        "        x=F.relu(x)\n",
        "        x=F.max_pool2d(x,(2,2))\n",
        "        x=self.bn1(x)\n",
        "        x=self.conv2(x)\n",
        "        x=F.relu(x)\n",
        "        x=F.max_pool2d(x,(2,2))\n",
        "        x=self.bn2(x)\n",
        "\n",
        "        x= torch.flatten(x,1)\n",
        "        x=self.fc1(x)\n",
        "        x=F.relu(x)\n",
        "        x=self.bn3(x)\n",
        "        x=self.fc2(x)\n",
        "        x=F.relu(x)\n",
        "        x=self.bn4(x)\n",
        "        x=self.fc3(x)\n",
        "        return x\n",
        ""
      ],
      "metadata": {
        "id": "DOQ_N-nikC4C"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= ConvNet()\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBym6SxKkD4g",
        "outputId": "ef55aa53-1602-4cfb-9646-1876d04ee74d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ConvNet(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (bn2): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv4): Conv2d(6, 28, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=700, out_features=120, bias=True)\n",
            "  (bn3): BatchNorm1d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (bn4): BatchNorm1d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=.001)"
      ],
      "metadata": {
        "id": "YzQamoCLkSzu"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.trainloader) #total number of image\n",
        "    model.train()\n",
        "\n",
        "    for batch, (image, label) in enumerate(dataloader):\n",
        "\n",
        "        pred = model(image)\n",
        "        loss = loss_fn(pred, label)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(image)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
      ],
      "metadata": {
        "id": "FABD-iHCuI9T"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    total_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in dataloader:\n",
        "            pred = model(image)\n",
        "            total_loss += loss_fn(pred, label).item()\n",
        "            correct += (pred.argmax(1) == label).type(torch.float).sum().item()\n",
        "\n",
        "    total_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test result: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {total_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "XGLw0jVCuON4"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_labels = [] #for confusion matrix\n",
        "predicted_labels = [] #for confusion matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "C7FcWiT-weBg"
      },
      "execution_count": 117,
      "outputs": []
    }
  ]
}